{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d2ba9ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing all the libraries\n",
    "import nltk\n",
    "from os import getcwd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.corpus import twitter_samples\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "551fffd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sets of positive and negative tweets\n",
    "pos_tweets = twitter_samples.strings('positive_tweets.json')\n",
    "neg_tweets = twitter_samples.strings('negative_tweets.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7f10d7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train-test spilt of 80% train set and 20% test set\n",
    "test_pos = pos_tweets[4000:]\n",
    "train_pos = pos_tweets[:4000]\n",
    "test_neg = neg_tweets[4000:]\n",
    "train_neg = neg_tweets[:4000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "5d815b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combining positive and negative tweets for train and test sets\n",
    "X_train = train_pos + train_neg \n",
    "X_test = test_pos + test_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "459d579a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating labels\n",
    "y_train = np.append(np.ones((len(train_pos), 1)), np.zeros((len(train_neg), 1)), axis=0)\n",
    "y_test = np.append(np.ones((len(test_pos), 1)), np.zeros((len(test_neg), 1)), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3c9c4307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000, 1)\n",
      "(2000, 1)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a30f4249",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_tweet(tweet):\n",
    "\n",
    "    stemmer = PorterStemmer()\n",
    "    stopwords_english = stopwords.words('english')\n",
    "    # remove stock market tickers like $GE\n",
    "    tweet = re.sub(r'\\$\\w*', '', tweet)\n",
    "    # remove old style retweet text \"RT\"\n",
    "    tweet = re.sub(r'^RT[\\s]+', '', tweet)\n",
    "    # remove hyperlinks\n",
    "    tweet = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', tweet)\n",
    "    # remove hashtags by only removing the hash # sign from the word\n",
    "    tweet = re.sub(r'#', '', tweet)\n",
    "    # tokenize tweets\n",
    "    tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True,\n",
    "                               reduce_len=True)\n",
    "    tweet_tokens = tokenizer.tokenize(tweet)\n",
    "\n",
    "    processed_tweets = []\n",
    "    for word in tweet_tokens:\n",
    "        if (word not in stopwords_english and  # remove stopwords\n",
    "                word not in string.punctuation):  # remove punctuation\n",
    "            stem_word = stemmer.stem(word)  # stemming word\n",
    "            processed_tweets.append(stem_word)\n",
    "\n",
    "    return processed_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b3a29818",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_list = np.squeeze(y_train).tolist() # numpy array to list\n",
    "\n",
    "# create a dictionary of frequenies mapping each (word, sentiment) pair to itsfrequency\n",
    "freqs = {}\n",
    "for y, tweet in zip(y_train_list, X_train):\n",
    "    for word in process_tweet(tweet):\n",
    "        pair = (word, y)\n",
    "        if pair in freqs:\n",
    "            freqs[pair] += 1\n",
    "        else:\n",
    "            freqs[pair] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "792c595e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z): \n",
    "    h = 1 / (1 + np.exp(-z))    \n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "17b276c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradientDescent(x, y, theta, alpha, num_iters):\n",
    "    \n",
    "    m = x.shape[0]\n",
    "    \n",
    "    for i in range(0, num_iters):\n",
    "        \n",
    "        # dot product of x and theta\n",
    "        z = np.dot(x,theta)\n",
    "        \n",
    "        # sigmoid of z\n",
    "        h = sigmoid(z)\n",
    "        \n",
    "        # cost function\n",
    "        J = -1./m * (np.dot(y.transpose(), np.log(h)) + np.dot((1-y).transpose(),np.log(1-h)))    \n",
    "\n",
    "        # update the weights of theta\n",
    "        theta = theta = theta - (alpha/m) * np.dot(x.transpose(),(h-y))\n",
    "        \n",
    "    J = float(J)\n",
    "    return J, theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b2027eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(tweet, freqs):\n",
    "\n",
    "    # process tweets\n",
    "    word_l = process_tweet(tweet)\n",
    "    \n",
    "    x = np.zeros((1, 3)) \n",
    "    \n",
    "    #set bias term to 1\n",
    "    x[0,0] = 1 \n",
    "        \n",
    "    for word in word_l:\n",
    "        \n",
    "        # increment the word count for the positive label 1\n",
    "        x[0,1] += freqs.get((word, 1.0),0)\n",
    "        \n",
    "        # increment the word count for the negative label 0\n",
    "        x[0,2] += freqs.get((word, 0.0),0)\n",
    "        \n",
    "        #print(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "985ee882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after training: 0.21085715.\n",
      "Resulting vector of weights: [1e-07, 0.00062146, -0.00063298]\n"
     ]
    }
   ],
   "source": [
    "X = np.zeros((len(X_train), 3))\n",
    "for i in range(len(X_train)):\n",
    "    X[i, :]= extract_features(X_train[i], freqs)\n",
    "\n",
    "# Applying gradient descent\n",
    "J, theta = gradientDescent(X, y_train, np.zeros((3, 1)), 1e-9, 2000)\n",
    "print(f\"Cost after training: {J:.8f}.\")\n",
    "print(f\"Resulting vector of weights: {[round(t, 8) for t in np.squeeze(theta)]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "08ddffe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_tweet(tweet, freqs, theta):\n",
    "    \n",
    "    x = extract_features(tweet,freqs)\n",
    "    \n",
    "    # prediction using x and theta\n",
    "    y_pred = sigmoid(np.dot(x,theta))\n",
    "        \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "2a05af67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_LR(X_test, y_test, freqs, theta):\n",
    "\n",
    "    y_hat = []\n",
    "    \n",
    "    for tweet in test_x:\n",
    "        # predict label\n",
    "        y_pred = predict_tweet(tweet, freqs, theta)\n",
    "        \n",
    "        if y_pred > 0.5:\n",
    "            y_hat.append(1)\n",
    "        else:\n",
    "            y_hat.append(0)\n",
    "\n",
    "    acc = (y_hat==np.squeeze(y_test)).sum()/len(X_test)\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "70d144d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR model's accuracy = 0.99550000\n"
     ]
    }
   ],
   "source": [
    "accuracy = test_LR(X_test, y_test, freqs, theta)\n",
    "print(f\"LR model's accuracy = {accuracy:.8f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "8bfd790f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['today', 'beauti', 'day', ':)']\n",
      "[[0.86193693]]\n",
      "Positive sentiment\n"
     ]
    }
   ],
   "source": [
    "my_tweet = 'Today is a beautiful day! :)'\n",
    "print(process_tweet(my_tweet))\n",
    "y_hat = predict_tweet(my_tweet, freqs, theta)\n",
    "print(y_hat)\n",
    "if y_hat > 0.5:\n",
    "    print('Positive sentiment')\n",
    "else: \n",
    "    print('Negative sentiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480854c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
